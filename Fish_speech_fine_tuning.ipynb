{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QgI0OPIxlOHl",
        "vxyojfW6mRlI"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNlgg5Fvb7ToIcco0A4WQxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lynnelynne99/python/blob/main/Fish_speech_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **ÏôÑÎ£åÎêú ÏûëÏóÖÏùÄ (O)ÌëúÏãúÌï® üôÉ**\n",
        "\n",
        "Îü∞ÌÉÄÏûÑ Ïú†Ìòï Î≥ÄÍ≤Ω> GPUÎ°ú ÏÑ§Ï†ï ÌïÑÏöî\n"
      ],
      "metadata": {
        "id": "daRwR1vYzQkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Îç∞Ïù¥ÌÑ∞ÏÖã Ï§ÄÎπÑ"
      ],
      "metadata": {
        "id": "oCsfmRfGzxN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ColabÏóêÏÑú Google DriveÎ•º ÎßàÏö¥Ìä∏(O)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6DrzLHVxmat",
        "outputId": "6849f45f-c650-40e8-e7f5-4d050ad17ca4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG7IlSwtt30o",
        "outputId": "67a2a3f7-3b56-41d2-df11-9ff62b276f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fish-speech'...\n",
            "remote: Enumerating objects: 5482, done.\u001b[K\n",
            "remote: Counting objects: 100% (1561/1561), done.\u001b[K\n",
            "remote: Compressing objects: 100% (306/306), done.\u001b[K\n",
            "remote: Total 5482 (delta 1324), reused 1257 (delta 1255), pack-reused 3921 (from 3)\u001b[K\n",
            "Receiving objects: 100% (5482/5482), 18.60 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (3639/3639), done.\n",
            "/content/fish-speech\n"
          ]
        }
      ],
      "source": [
        "#(1) Fish Speech Ï†ÄÏû•ÏÜå ÌÅ¥Î°† Î∞è Í∏∞Î≥∏ ÏÑ§Ï†ï(O)\n",
        "\n",
        "!git clone https://github.com/fishaudio/fish-speech.git\n",
        "%cd fish-speech"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(2) Hugging FaceÏóêÏÑú Î™®Îç∏ Îã§Ïö¥Î°úÎìú(o)\n",
        "\n",
        "!huggingface-cli download fishaudio/fish-speech-1.5 --local-dir checkpoints/fish-speech-1.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1lbDjBn2uINH",
        "outputId": "c19e978b-527f-40a3-8dee-6c2f9ad5d5c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]\rFetching 7 files: 100% 7/7 [00:00<00:00, 4460.67it/s]\n",
            "/content/checkpoints/fish-speech-1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(3) Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨ÏÑ±**\n",
        "\n",
        "`.wav` / `.lab` ÌååÏùº Ï§ÄÎπÑ"
      ],
      "metadata": {
        "id": "GPn-c0i9ucNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(4)ÏùåÏÑ± Îç∞Ïù¥ÌÑ∞ Ï†ïÏ†úÎ•º ÏúÑÌï¥ ÏÑ§Ïπò(o)\n",
        "!pip install fish-audio-preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S-Rcu77wu_JH",
        "outputId": "85d4528e-e572-4441-a7a0-67abdcb0e82c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fish-audio-preprocess\n",
            "  Downloading fish_audio_preprocess-0.2.8-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from fish-audio-preprocess) (4.67.1)\n",
            "Collecting demucs>=4.0.0 (from fish-audio-preprocess)\n",
            "  Downloading demucs-4.0.1.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: loguru>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from fish-audio-preprocess) (0.7.3)\n",
            "Collecting pyloudnorm>=0.1.1 (from fish-audio-preprocess)\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from fish-audio-preprocess) (3.10.0)\n",
            "Requirement already satisfied: librosa>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from fish-audio-preprocess) (0.10.2.post1)\n",
            "Collecting richuru>=0.1.1 (from fish-audio-preprocess)\n",
            "  Downloading richuru-0.1.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting praat-parselmouth>=0.4.3 (from fish-audio-preprocess)\n",
            "  Downloading praat_parselmouth-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from fish-audio-preprocess) (8.1.8)\n",
            "Collecting openai-whisper (from fish-audio-preprocess)\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dora-search (from demucs>=4.0.0->fish-audio-preprocess)\n",
            "  Downloading dora_search-0.1.12.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from demucs>=4.0.0->fish-audio-preprocess) (0.8.0)\n",
            "Collecting julius>=0.2.3 (from demucs>=4.0.0->fish-audio-preprocess)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lameenc>=1.2 (from demucs>=4.0.0->fish-audio-preprocess)\n",
            "  Downloading lameenc-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting openunmix (from demucs>=4.0.0->fish-audio-preprocess)\n",
            "  Downloading openunmix-1.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from demucs>=4.0.0->fish-audio-preprocess) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from demucs>=4.0.0->fish-audio-preprocess) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio>=0.8 in /usr/local/lib/python3.11/dist-packages (from demucs>=4.0.0->fish-audio-preprocess) (2.5.1+cu124)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->fish-audio-preprocess) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->fish-audio-preprocess) (2.8.2)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from pyloudnorm>=0.1.1->fish-audio-preprocess) (1.0.0)\n",
            "Requirement already satisfied: rich>=12.4.4 in /usr/local/lib/python3.11/dist-packages (from richuru>=0.1.1->fish-audio-preprocess) (13.9.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper->fish-audio-preprocess) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper->fish-audio-preprocess)\n",
            "  Using cached tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper->fish-audio-preprocess) (3.1.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.9.0->fish-audio-preprocess) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.9.0->fish-audio-preprocess) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.9.0->fish-audio-preprocess) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->fish-audio-preprocess) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.4.4->richuru>=0.1.1->fish-audio-preprocess) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.4.4->richuru>=0.1.1->fish-audio-preprocess) (2.18.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.9.0->fish-audio-preprocess) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa>=0.9.0->fish-audio-preprocess) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (1.3.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from dora-search->demucs>=4.0.0->fish-audio-preprocess) (2.3.0)\n",
            "Collecting retrying (from dora-search->demucs>=4.0.0->fish-audio-preprocess)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting submitit (from dora-search->demucs>=4.0.0->fish-audio-preprocess)\n",
            "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting treetable (from dora-search->demucs>=4.0.0->fish-audio-preprocess)\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper->fish-audio-preprocess) (2024.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.9.0->fish-audio-preprocess) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.4.4->richuru>=0.1.1->fish-audio-preprocess) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.0->fish-audio-preprocess) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.0->fish-audio-preprocess) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.0->fish-audio-preprocess) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.0->fish-audio-preprocess) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->demucs>=4.0.0->fish-audio-preprocess) (3.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->dora-search->demucs>=4.0.0->fish-audio-preprocess) (4.9.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->dora-search->demucs>=4.0.0->fish-audio-preprocess) (3.1.1)\n",
            "Downloading fish_audio_preprocess-0.2.8-py3-none-any.whl (28 kB)\n",
            "Downloading praat_parselmouth-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading richuru-0.1.1-py3-none-any.whl (4.4 kB)\n",
            "Downloading lameenc-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openunmix-1.3.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: demucs, openai-whisper, julius, dora-search, treetable\n",
            "  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demucs: filename=demucs-4.0.1-py3-none-any.whl size=78388 sha256=9928a8a0ba6ff7751136467b0a0959cd2cec1a7fabe7892469387d8b9dd67b3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/06/a3/83489d50c9f015fa981a2a7bb08fcede75120a0de56775353f\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=d9b2ae6dae62333941c5452d8047f0f7332a2a088af86a22b2baad6ef6a88724\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=5946b9c0e41737f6a8a2a7644c4398e80dab6dc4a5213d345901d47028d603e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75163 sha256=672b9a39c7ca50bab3b57d94b88a385ba7d73816b50f990ace4a8976ffdacac6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/f3/a9/2fd1ebbd64c4b2a1e53c81bf25282567a80802ceedfedcab4a\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7334 sha256=a096a63e5a044be6229fd650848278db5cfef208db24e67147277e2447e9f87c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/c9/6a/3ee58e3f4ed63e61de2a515cdb75438521f0372a1f0086be79\n",
            "Successfully built demucs openai-whisper julius dora-search treetable\n",
            "Installing collected packages: lameenc, treetable, submitit, retrying, praat-parselmouth, tiktoken, pyloudnorm, richuru, openai-whisper, julius, dora-search, openunmix, demucs, fish-audio-preprocess\n",
            "Successfully installed demucs-4.0.1 dora-search-0.1.12 fish-audio-preprocess-0.2.8 julius-0.2.7 lameenc-1.8.1 openai-whisper-20240930 openunmix-1.3.0 praat-parselmouth-0.4.5 pyloudnorm-0.1.1 retrying-1.3.4 richuru-0.1.1 submitit-1.5.2 tiktoken-0.8.0 treetable-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Í∏∞Ï°¥Ïóê SPK1 Ìè¥ÎçîÏóê ÏûàÎäî ÌååÏùºÏùÑ data-rawÎ°ú (ÏÉùÏÑ± ÌõÑ Î≥µÏÇ¨)(o)\n",
        "!mkdir -p /content/data-raw\n",
        "!cp -r /content/drive/MyDrive/fish-speech/data/SPK1/* /content/data-raw/"
      ],
      "metadata": {
        "id": "OAR-l0L_x3U8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î≥µÏÇ¨Í∞Ä Ïûò ÎêòÏóàÎäîÏßÄ ÌôïÏù∏(O)\n",
        "!ls -lh /content/data-raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiiRxq0NyQQ_",
        "outputId": "95f81270-5a9e-4f8f-de99-d2799936b733"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 5.6M\n",
            "-rw------- 1 root root  197 Feb 11 02:57 1.lab\n",
            "-rw------- 1 root root 5.6M Feb 11 02:57 1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (4)ÏóêÏÑú ÏÑ§ÏπòÌñàÎçò fish-audio-preprocessÎ°ú ÏùåÏÑ± Îç∞Ïù¥ÌÑ∞ Ï†ïÏ†ú ÏûëÏóÖ Ïã§Ìñâ(O)\n",
        "!fap loudness-norm data-raw data --clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tg9uiEKydG1",
        "outputId": "90610ee8-200c-4e6c-f85f-f97194e418f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2025-02-11 02:57:58.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_audio_preprocess.cli.loudness_norm\u001b[0m:\u001b[36mloudness_norm\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mFound 1 files, normalizing loudness\u001b[0m\n",
            "Preparing tasks: 100% 1/1 [00:00<00:00, 18.91it/s]\n",
            "Processing:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "Processing: 100% 1/1 [00:00<00:00,  5.03it/s]\n",
            "\u001b[32m2025-02-11 02:57:58.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_audio_preprocess.cli.loudness_norm\u001b[0m:\u001b[36mloudness_norm\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2025-02-11 02:57:58.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_audio_preprocess.cli.loudness_norm\u001b[0m:\u001b[36mloudness_norm\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mTotal: 1, Skipped: 0\u001b[0m\n",
            "\u001b[32m2025-02-11 02:57:58.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_audio_preprocess.cli.loudness_norm\u001b[0m:\u001b[36mloudness_norm\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mOutput directory: data\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ogn-GCU60OY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Semantic Token Ï∂îÏ∂ú, Îç∞Ïù¥ÌÑ∞ÏÖã Ìå®ÌÇπ\n",
        "`.wav` ÌååÏùºÏùÑ VQGANÏùÑ ÌôúÏö©Ìï¥ `.npy` ÌååÏùºÎ°ú Î≥ÄÌôò\n",
        "\n"
      ],
      "metadata": {
        "id": "5nT1-UHVz0m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) VQGAN Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Îã§Ïö¥Î°úÎìú(O)\n",
        "!huggingface-cli download fishaudio/fish-speech-1.5 \\\n",
        "    --local-dir checkpoints/fish-speech-1.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wuD_qkiIz43C",
        "outputId": "ad5d82a9-c4dc-43f9-eaea-0ec6a05a1fb8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]\rFetching 7 files: 100% 7/7 [00:00<00:00, 4382.11it/s]\n",
            "/content/checkpoints/fish-speech-1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hydra-core #hydra Î™®Îìà ÏÑ§Ïπò\n",
        "!pip install hydra-core loguru click numpy tqdm torch torchvision torchaudio # Ï∂îÍ∞Ä ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UeOo1lwa5LII",
        "outputId": "c0ca33e1-26f2-45ce-8b85-291518f33a8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core) (24.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (0.7.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (8.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# portaudio ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
        "!sudo apt-get install portaudio19-dev\n",
        "!pip install pyaudio\n",
        "!pip install -e /content/fish-speech #fish_speech Îã§Ïãú ÏÑ§Ïπò"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pQ0X151_7nf4",
        "outputId": "3181456c-ea23-4c3d-a090-459302f321df"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 2s (123 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp311-cp311-linux_x86_64.whl size=67395 sha256=7210b216f57a5780116ac1ead656b9275dd0cbdd93d0792d8282815a1dc08514\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/b1/c1/67e4ef443de2665d86031d4760508094eab5de37d5d64d9c27\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.14\n",
            "Obtaining file:///content/fish-speech\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (4.48.2)\n",
            "Collecting datasets==2.18.0 (from fish-speech==0.1.0)\n",
            "  Using cached datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning>=2.1.0 (from fish-speech==0.1.0)\n",
            "  Using cached lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: tensorboard>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (8.4.0)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.8.0)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.10.2.post1)\n",
            "Requirement already satisfied: rich>=13.5.3 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (13.9.4)\n",
            "Collecting gradio>5.0.0 (from fish-speech==0.1.0)\n",
            "  Using cached gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: wandb>=0.15.11 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.19.6)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.70.0)\n",
            "Collecting kui>=1.6.0 (from fish-speech==0.1.0)\n",
            "  Using cached kui-1.8.1-py3-none-any.whl.metadata (984 bytes)\n",
            "Collecting uvicorn>=0.30.0 (from fish-speech==0.1.0)\n",
            "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: loguru>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.7.3)\n",
            "Collecting loralib>=0.1.2 (from fish-speech==0.1.0)\n",
            "  Using cached loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyrootutils>=1.0.4 (from fish-speech==0.1.0)\n",
            "  Using cached pyrootutils-1.0.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting vector_quantize_pytorch==1.14.24 (from fish-speech==0.1.0)\n",
            "  Using cached vector_quantize_pytorch-1.14.24-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting resampy>=0.4.3 (from fish-speech==0.1.0)\n",
            "  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting einx==0.2.2 (from einx[torch]==0.2.2->fish-speech==0.1.0)\n",
            "  Using cached einx-0.2.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: zstandard>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.23.0)\n",
            "Collecting pydub (from fish-speech==0.1.0)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.2.14)\n",
            "Collecting faster_whisper (from fish-speech==0.1.0)\n",
            "  Using cached faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting modelscope==1.17.1 (from fish-speech==0.1.0)\n",
            "  Using cached modelscope-1.17.1-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting funasr==1.1.5 (from fish-speech==0.1.0)\n",
            "  Using cached funasr-1.1.5-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting opencc-python-reimplemented==0.1.7 (from fish-speech==0.1.0)\n",
            "  Using cached opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting silero-vad (from fish-speech==0.1.0)\n",
            "  Using cached silero_vad-5.1.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting ormsgpack (from fish-speech==0.1.0)\n",
            "  Using cached ormsgpack-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.8.0)\n",
            "Collecting pydantic==2.9.2 (from fish-speech==0.1.0)\n",
            "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (5.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (17.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.6)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (1.13.1)\n",
            "Collecting jamo (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.13.1)\n",
            "Collecting kaldiio>=2.17.0 (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached kaldiio-2.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch-complex (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached torch_complex-0.4.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.42.1)\n",
            "Collecting pytorch-wpe (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached pytorch_wpe-0.0.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.8.1)\n",
            "Collecting oss2 (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached oss2-2.19.1-py3-none-any.whl\n",
            "Collecting umap-learn (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaconv (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached jaconv-0.4.0-py3-none-any.whl\n",
            "Collecting tensorboardX (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.17.1->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic==2.9.2->fish-speech==0.1.0)\n",
            "  Using cached pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (4.12.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (11.1.0)\n",
            "Collecting python-multipart>=0.0.18 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio>5.0.0->fish-speech==0.1.0)\n",
            "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.15.1)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio>5.0.0->fish-speech==0.1.0) (14.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (4.9.3)\n",
            "Collecting baize>=0.20.0 (from kui>=1.6.0->fish-speech==0.1.0)\n",
            "  Using cached baize-0.22.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.61.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.1.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Using cached lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Using cached torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting python-dotenv>=0.20.0 (from pyrootutils>=1.0.4->fish-speech==0.1.0)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.1.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->fish-speech==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.5.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (1.3.4)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster_whisper->fish-speech==0.1.0)\n",
            "  Using cached ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster_whisper->fish-speech==0.1.0)\n",
            "  Using cached onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from faster_whisper->fish-speech==0.1.0)\n",
            "  Using cached av-14.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: torchaudio>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from silero-vad->fish-speech==0.1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (1.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.3->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.10.1->fish-speech==0.1.0) (0.44.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0) (25.1.24)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0->fish-speech==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.10.1->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>5.0.0->fish-speech==0.1.0) (1.5.4)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached crcmod-1.7-cp311-cp311-linux_x86_64.whl\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached aliyun_python_sdk_core-2.16.0-py3-none-any.whl\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Using cached jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0) (43.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (5.0.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Using cached datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "Using cached einx-0.2.2-py3-none-any.whl (101 kB)\n",
            "Using cached funasr-1.1.5-py3-none-any.whl (649 kB)\n",
            "Using cached modelscope-1.17.1-py3-none-any.whl (5.7 MB)\n",
            "Using cached opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "Using cached vector_quantize_pytorch-1.14.24-py3-none-any.whl (36 kB)\n",
            "Using cached pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Using cached gradio-5.15.0-py3-none-any.whl (57.8 MB)\n",
            "Using cached gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "Using cached kui-1.8.1-py3-none-any.whl (65 kB)\n",
            "Using cached lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "Using cached loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Using cached pyrootutils-1.0.4-py3-none-any.whl (5.8 kB)\n",
            "Using cached resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "Using cached faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "Using cached ormsgpack-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Using cached silero_vad-5.1.2-py3-none-any.whl (5.0 MB)\n",
            "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached av-14.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.5 MB)\n",
            "Using cached baize-0.22.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (733 kB)\n",
            "Using cached ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "Using cached kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Using cached lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Using cached onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Using cached ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Using cached starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Using cached torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "Using cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Using cached jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "Using cached pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Using cached torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Using cached umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Using cached aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "Using cached pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: fish-speech\n",
            "  Building editable for fish-speech (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fish-speech: filename=fish_speech-0.1.0-0.editable-py3-none-any.whl size=10405 sha256=82cbd3ca2a73a5b630e6e6c6089af9fae76b7565b73a11256dd8ad7bd9215beb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oir_209k/wheels/1d/8d/79/64aa115a26c1628f19c01f0b6214e49c83c75365353fa810b5\n",
            "Successfully built fish-speech\n",
            "Installing collected packages: pydub, opencc-python-reimplemented, jamo, jaconv, crcmod, xxhash, uvicorn, torch-complex, tomlkit, tensorboardX, semantic-version, ruff, pytorch-wpe, python-multipart, python-dotenv, pydantic-core, pycryptodome, pyarrow-hotfix, ormsgpack, markupsafe, loralib, lightning-utilities, kaldiio, jmespath, humanfriendly, fsspec, ffmpy, dill, ctranslate2, baize, av, aiofiles, starlette, resampy, pyrootutils, pydantic, multiprocess, modelscope, einx, coloredlogs, safehttpx, pynndescent, onnxruntime, kui, gradio-client, fastapi, aliyun-python-sdk-core, vector_quantize_pytorch, umap-learn, torchmetrics, gradio, faster_whisper, datasets, aliyun-python-sdk-kms, silero-vad, pytorch-lightning, oss2, lightning, funasr, fish-speech\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 av-14.1.0 baize-0.22.2 coloredlogs-15.0.1 crcmod-1.7 ctranslate2-4.5.0 datasets-2.18.0 dill-0.3.8 einx-0.2.2 fastapi-0.115.8 faster_whisper-1.1.1 ffmpy-0.5.0 fish-speech-0.1.0 fsspec-2024.2.0 funasr-1.1.5 gradio-5.15.0 gradio-client-1.7.0 humanfriendly-10.0 jaconv-0.4.0 jamo-0.4.1 jmespath-0.10.0 kaldiio-2.18.0 kui-1.8.1 lightning-2.5.0.post0 lightning-utilities-0.12.0 loralib-0.1.2 markupsafe-2.1.5 modelscope-1.17.1 multiprocess-0.70.16 onnxruntime-1.20.1 opencc-python-reimplemented-0.1.7 ormsgpack-1.7.0 oss2-2.19.1 pyarrow-hotfix-0.6 pycryptodome-3.21.0 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 pynndescent-0.5.13 pyrootutils-1.0.4 python-dotenv-1.0.1 python-multipart-0.0.20 pytorch-lightning-2.5.0.post0 pytorch-wpe-0.0.1 resampy-0.4.3 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 silero-vad-5.1.2 starlette-0.45.3 tensorboardX-2.6.2.2 tomlkit-0.13.2 torch-complex-0.4.4 torchmetrics-1.6.1 umap-learn-0.5.7 uvicorn-0.34.0 vector_quantize_pytorch-1.14.24 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) Semantic Token Ï∂îÏ∂ú\n",
        "!python /content/fish-speech/tools/vqgan/extract_vq.py /content/data \\\n",
        "    --num-workers 1 --batch-size 16 \\\n",
        "    --config-name \"firefly_gan_vq\" \\\n",
        "    --checkpoint-path \"/content/checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKqweVd70T-L",
        "outputId": "88673f50-800f-432b-a326-e66618a89753"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2025-02-11 04:25:49.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m189\u001b[0m | RANK: 0 / 1 - \u001b[1mStarting worker\u001b[0m\n",
            "Found 1 files\n",
            "\u001b[32m2025-02-11 04:25:49.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m200\u001b[0m | RANK: 0 / 1 - \u001b[1mProcessing 1/1 files\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:445: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:630: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/lookup_free_quantization.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/content/fish-speech/tools/vqgan/extract_vq.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\n",
            "\u001b[32m2025-02-11 04:25:51.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m75\u001b[0m | RANK: 0 / 1 - \u001b[1mLoaded model\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/residual_fsq.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled = False):\n",
            "\u001b[32m2025-02-11 04:25:51.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m226\u001b[0m | RANK: 0 / 1 - \u001b[1mFinished processing 1 files, 0.05 hours of audio\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/fish-speech/data/SPK1/ # Ïù¥ Í≤ΩÎ°úÏóê 1.lab  1.npy Í∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏(O)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEDV4gTKtg2",
        "outputId": "cfc3a8aa-8eb6-4460-ad3c-45c6cfab6dd5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.lab  1.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) ProtobufÏúºÎ°ú Îç∞Ïù¥ÌÑ∞ÏÖã Ìå®ÌÇπ: Ï∂îÏ∂úÎêú semantic tokenÏùÑ protobuf ÌòïÏãùÏúºÎ°ú Î≥ÄÌôòÌïòÏó¨ ÌõàÎ†® Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù Ìå®ÌÇπÌïòÎäî Í≥ºÏ†ï\n",
        "!python /content/fish-speech/tools/llama/build_dataset.py \\\n",
        "    --input \"/content/fish-speech/data\" \\\n",
        "    --output \"/content/fish-speech/data/protos\" \\\n",
        "    --text-extension .lab \\\n",
        "    --num-workers 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwIfC_DK9k7t",
        "outputId": "eef9b3b2-f966-4d54-b4ca-9c15b3b9001e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0it [00:00, ?it/s]\n",
            "\rLoading /content/fish-speech/data: 0it [00:00, ?it/s]\u001b[A\rLoading /content/fish-speech/data: 1it [00:00, 983.42it/s]\n",
            "\n",
            "\rGrouping /content/fish-speech/data:   0% 0/1 [00:00<?, ?it/s]\u001b[A\rGrouping /content/fish-speech/data: 100% 1/1 [00:00<00:00, 4934.48it/s]\n",
            "\u001b[32m2025-02-11 04:20:54.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtask_generator_folder\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mFound 1 groups in /content/fish-speech/data, ['/content/fish-speech/data/SPK1']...\u001b[0m\n",
            "\r1it [00:00, 91.06it/s]\n",
            "\u001b[32m2025-02-11 04:20:54.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mFinished writing 1 shards to /content/fish-speech/data/protos\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. LoRAÎ•º ÏÇ¨Ïö©Ìïú Fine-tuning ÏãúÏûë\n",
        "> LoRA ÌååÏù∏ÌäúÎãùÏùÑ ÏúÑÌïú ÌïÑÏàò ÌååÏùº\n",
        "\n",
        "1.   `.lab` ÌååÏùº:\n",
        "   *   ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î•º Ìè¨Ìï®ÌïòÎäî ÌååÏùº (Ïòà: Î≥¥Ìóò ÏÉÅÎã¥ Î¨∏Ïû•)\n",
        "   *   `SPK1/1.lab`, `SPK1/2.lab`, ... ÌòïÏãù\n",
        "2.   `.npy` ÌååÏùº:\n",
        "   *   .wav ÌååÏùºÏùÑ Î≥ÄÌôòÌïú Î≤°ÌÑ∞ Îç∞Ïù¥ÌÑ∞\n",
        "   *   VQGAN ÎòêÎäî VQ-VAE Í∞ôÏùÄ Ïò§ÎîîÏò§ Ïù∏ÏΩîÎçîÎ•º ÏÇ¨Ïö©Ìï¥ Î≥ÄÌôò\n",
        "   *   `SPK1/1.npy`, `SPK1/2.npy`, ... ÌòïÏãù\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "    1Ô∏è‚É£ .wav ÌååÏùºÏùÄ Î™®Îç∏ ÏûÖÎ†•ÏúºÎ°ú ÏßÅÏ†ë ÏÇ¨Ïö©ÎêòÏßÄ ÏïäÍ≥†, .npyÎ°ú Î≥ÄÌôòÎêú Îí§ ÏÇ¨Ïö©Îê®\n",
        "    - .wav ‚Üí VQGAN Î≥ÄÌôò ‚Üí .npy (Ïò§ÎîîÏò§ ÌäπÏßï Î≤°ÌÑ∞)\n",
        "    - Î™®Îç∏ÏùÄ ÏßÅÏ†ë .wavÎ•º ÌïôÏäµÌïòÏßÄ ÏïäÍ≥† .npyÎ•º ÏÇ¨Ïö©Ìï®\n",
        "\n",
        "    2Ô∏è‚É£ ÌååÏù∏ÌäúÎãù Ïãú Î™®Îç∏Ïù¥ ÌïôÏäµÌïòÎäî Í≤ÉÏùÄ .lab(ÌÖçÏä§Ìä∏)Í≥º .npy(Ïò§ÎîîÏò§ ÌäπÏßï Î≤°ÌÑ∞)\n",
        "    - .lab: ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ (ÏùåÏÑ±Ïù¥ Ïñ¥Îñ§ Î¨∏Ïû•ÏùÑ ÏùòÎØ∏ÌïòÎäîÏßÄ)\n",
        "    - .npy: Î≥ÄÌôòÎêú ÏùåÏÑ± Îç∞Ïù¥ÌÑ∞ (Ïò§ÎîîÏò§ ÏûÑÎ≤†Îî©)\n",
        "\n",
        "    3Ô∏è‚É£ Îî∞ÎùºÏÑú .wavÍ∞Ä ÏóÜÏñ¥ÎèÑ .npyÍ∞Ä Ï†úÎåÄÎ°ú ÏÉùÏÑ±ÎêòÏñ¥ ÏûàÏúºÎ©¥ Î¨∏Ï†úÏóÜÏù¥ ÏßÑÌñâ Í∞ÄÎä•\n",
        "    - .lab + .npyÎßå ÏûàÏúºÎ©¥ Î™®Îç∏Ïù¥ ÌïÑÏöîÌïú Î™®Îì† Ï†ïÎ≥¥Î•º ÌïôÏäµ Í∞ÄÎä•\n",
        "    - .wav ÏóÜÏù¥ÎèÑ LoRA ÌååÏù∏ÌäúÎãù ÏàòÌñâ Í∞ÄÎä•"
      ],
      "metadata": {
        "id": "FoSDVHtzL6DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/fish-speech/data/protos/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU4R6scSM1_t",
        "outputId": "3c8fc2bd-fdb2-401c-c5f6-3420936493ef"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 60K\n",
            "-rw-r--r-- 1 root root 58K Feb 11 04:01 00000000.protos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fish-speech/fish_speech/train.py --config-name text2semantic_finetune \\\n",
        "    project=my_fish_speech \\\n",
        "    +lora@model.model.lora_config=r_8_alpha_16\n",
        "\n",
        "\n",
        "# --config-name text2semantic_finetune: text2semantic Î™®Îç∏ÏùÑ fine-tuning\n",
        "# project=my_fish_speech: Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† ÌîÑÎ°úÏ†ùÌä∏Î™Ö\n",
        "# +lora@model.model.lora_config=r_8_alpha_16: LoRAÎ•º Ï†ÅÏö©Ìïú Fine-tuning ÏàòÌñâ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iXtCuIM2LfSc",
        "outputId": "cdf69a57-f859-4ee2-ea69-efa514c666b2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-02-11 08:07:04,095][__main__][INFO] - [rank: 0] Instantiating datamodule <fish_speech.datasets.semantic.SemanticDataModule>\n",
            "[2025-02-11 08:07:04,116][datasets][INFO] - PyTorch version 2.5.1+cu124 available.\n",
            "[2025-02-11 08:07:04,116][datasets][INFO] - TensorFlow version 2.18.0 available.\n",
            "[2025-02-11 08:07:04,117][datasets][INFO] - JAX version 0.4.33 available.\n",
            "[2025-02-11 08:07:04,805][__main__][INFO] - [rank: 0] Instantiating model <fish_speech.models.text2semantic.lit_module.TextToSemantic>\n",
            "[2025-02-11 08:07:04,818][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] Override max_seq_len to 4096\n",
            "[2025-02-11 08:07:04,988][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] Loading model from checkpoints/fish-speech-1.5, config: DualARModelArgs(model_type='dual_ar', vocab_size=102048, n_layer=24, n_head=16, dim=1024, intermediate_size=4096, n_local_heads=2, head_dim=64, rope_base=1000000.0, norm_eps=1e-06, max_seq_len=4096, dropout=0.0, tie_word_embeddings=False, attention_qkv_bias=False, codebook_size=1024, num_codebooks=8, use_gradient_checkpointing=True, initializer_range=0.02, is_reward_model=False, share_codebook_embeddings=True, scale_codebook_embeddings=False, n_fast_layer=4, fast_dim=1024, fast_n_head=16, fast_n_local_heads=2, fast_head_dim=64, fast_intermediate_size=4096, fast_attention_qkv_bias=False)\n",
            "[2025-02-11 08:07:24,233][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] LoRA setup: LoraConfig(r=8, lora_alpha=16, lora_dropout=0.01)\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.255\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.256\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.257\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.307\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.310\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.312\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_A\u001b[0m\n",
            "\u001b[32m2025-02-11 08:07:24.314\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_B\u001b[0m\n",
            "[2025-02-11 08:07:24,383][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] Loaded weights with error: _IncompatibleKeys(missing_keys=['embeddings.lora_A', 'embeddings.lora_B', 'codebook_embeddings.lora_A', 'codebook_embeddings.lora_B', 'layers.0.attention.wqkv.lora_A', 'layers.0.attention.wqkv.lora_B', 'layers.0.attention.wo.lora_A', 'layers.0.attention.wo.lora_B', 'layers.0.feed_forward.w1.lora_A', 'layers.0.feed_forward.w1.lora_B', 'layers.0.feed_forward.w3.lora_A', 'layers.0.feed_forward.w3.lora_B', 'layers.0.feed_forward.w2.lora_A', 'layers.0.feed_forward.w2.lora_B', 'layers.1.attention.wqkv.lora_A', 'layers.1.attention.wqkv.lora_B', 'layers.1.attention.wo.lora_A', 'layers.1.attention.wo.lora_B', 'layers.1.feed_forward.w1.lora_A', 'layers.1.feed_forward.w1.lora_B', 'layers.1.feed_forward.w3.lora_A', 'layers.1.feed_forward.w3.lora_B', 'layers.1.feed_forward.w2.lora_A', 'layers.1.feed_forward.w2.lora_B', 'layers.2.attention.wqkv.lora_A', 'layers.2.attention.wqkv.lora_B', 'layers.2.attention.wo.lora_A', 'layers.2.attention.wo.lora_B', 'layers.2.feed_forward.w1.lora_A', 'layers.2.feed_forward.w1.lora_B', 'layers.2.feed_forward.w3.lora_A', 'layers.2.feed_forward.w3.lora_B', 'layers.2.feed_forward.w2.lora_A', 'layers.2.feed_forward.w2.lora_B', 'layers.3.attention.wqkv.lora_A', 'layers.3.attention.wqkv.lora_B', 'layers.3.attention.wo.lora_A', 'layers.3.attention.wo.lora_B', 'layers.3.feed_forward.w1.lora_A', 'layers.3.feed_forward.w1.lora_B', 'layers.3.feed_forward.w3.lora_A', 'layers.3.feed_forward.w3.lora_B', 'layers.3.feed_forward.w2.lora_A', 'layers.3.feed_forward.w2.lora_B', 'layers.4.attention.wqkv.lora_A', 'layers.4.attention.wqkv.lora_B', 'layers.4.attention.wo.lora_A', 'layers.4.attention.wo.lora_B', 'layers.4.feed_forward.w1.lora_A', 'layers.4.feed_forward.w1.lora_B', 'layers.4.feed_forward.w3.lora_A', 'layers.4.feed_forward.w3.lora_B', 'layers.4.feed_forward.w2.lora_A', 'layers.4.feed_forward.w2.lora_B', 'layers.5.attention.wqkv.lora_A', 'layers.5.attention.wqkv.lora_B', 'layers.5.attention.wo.lora_A', 'layers.5.attention.wo.lora_B', 'layers.5.feed_forward.w1.lora_A', 'layers.5.feed_forward.w1.lora_B', 'layers.5.feed_forward.w3.lora_A', 'layers.5.feed_forward.w3.lora_B', 'layers.5.feed_forward.w2.lora_A', 'layers.5.feed_forward.w2.lora_B', 'layers.6.attention.wqkv.lora_A', 'layers.6.attention.wqkv.lora_B', 'layers.6.attention.wo.lora_A', 'layers.6.attention.wo.lora_B', 'layers.6.feed_forward.w1.lora_A', 'layers.6.feed_forward.w1.lora_B', 'layers.6.feed_forward.w3.lora_A', 'layers.6.feed_forward.w3.lora_B', 'layers.6.feed_forward.w2.lora_A', 'layers.6.feed_forward.w2.lora_B', 'layers.7.attention.wqkv.lora_A', 'layers.7.attention.wqkv.lora_B', 'layers.7.attention.wo.lora_A', 'layers.7.attention.wo.lora_B', 'layers.7.feed_forward.w1.lora_A', 'layers.7.feed_forward.w1.lora_B', 'layers.7.feed_forward.w3.lora_A', 'layers.7.feed_forward.w3.lora_B', 'layers.7.feed_forward.w2.lora_A', 'layers.7.feed_forward.w2.lora_B', 'layers.8.attention.wqkv.lora_A', 'layers.8.attention.wqkv.lora_B', 'layers.8.attention.wo.lora_A', 'layers.8.attention.wo.lora_B', 'layers.8.feed_forward.w1.lora_A', 'layers.8.feed_forward.w1.lora_B', 'layers.8.feed_forward.w3.lora_A', 'layers.8.feed_forward.w3.lora_B', 'layers.8.feed_forward.w2.lora_A', 'layers.8.feed_forward.w2.lora_B', 'layers.9.attention.wqkv.lora_A', 'layers.9.attention.wqkv.lora_B', 'layers.9.attention.wo.lora_A', 'layers.9.attention.wo.lora_B', 'layers.9.feed_forward.w1.lora_A', 'layers.9.feed_forward.w1.lora_B', 'layers.9.feed_forward.w3.lora_A', 'layers.9.feed_forward.w3.lora_B', 'layers.9.feed_forward.w2.lora_A', 'layers.9.feed_forward.w2.lora_B', 'layers.10.attention.wqkv.lora_A', 'layers.10.attention.wqkv.lora_B', 'layers.10.attention.wo.lora_A', 'layers.10.attention.wo.lora_B', 'layers.10.feed_forward.w1.lora_A', 'layers.10.feed_forward.w1.lora_B', 'layers.10.feed_forward.w3.lora_A', 'layers.10.feed_forward.w3.lora_B', 'layers.10.feed_forward.w2.lora_A', 'layers.10.feed_forward.w2.lora_B', 'layers.11.attention.wqkv.lora_A', 'layers.11.attention.wqkv.lora_B', 'layers.11.attention.wo.lora_A', 'layers.11.attention.wo.lora_B', 'layers.11.feed_forward.w1.lora_A', 'layers.11.feed_forward.w1.lora_B', 'layers.11.feed_forward.w3.lora_A', 'layers.11.feed_forward.w3.lora_B', 'layers.11.feed_forward.w2.lora_A', 'layers.11.feed_forward.w2.lora_B', 'layers.12.attention.wqkv.lora_A', 'layers.12.attention.wqkv.lora_B', 'layers.12.attention.wo.lora_A', 'layers.12.attention.wo.lora_B', 'layers.12.feed_forward.w1.lora_A', 'layers.12.feed_forward.w1.lora_B', 'layers.12.feed_forward.w3.lora_A', 'layers.12.feed_forward.w3.lora_B', 'layers.12.feed_forward.w2.lora_A', 'layers.12.feed_forward.w2.lora_B', 'layers.13.attention.wqkv.lora_A', 'layers.13.attention.wqkv.lora_B', 'layers.13.attention.wo.lora_A', 'layers.13.attention.wo.lora_B', 'layers.13.feed_forward.w1.lora_A', 'layers.13.feed_forward.w1.lora_B', 'layers.13.feed_forward.w3.lora_A', 'layers.13.feed_forward.w3.lora_B', 'layers.13.feed_forward.w2.lora_A', 'layers.13.feed_forward.w2.lora_B', 'layers.14.attention.wqkv.lora_A', 'layers.14.attention.wqkv.lora_B', 'layers.14.attention.wo.lora_A', 'layers.14.attention.wo.lora_B', 'layers.14.feed_forward.w1.lora_A', 'layers.14.feed_forward.w1.lora_B', 'layers.14.feed_forward.w3.lora_A', 'layers.14.feed_forward.w3.lora_B', 'layers.14.feed_forward.w2.lora_A', 'layers.14.feed_forward.w2.lora_B', 'layers.15.attention.wqkv.lora_A', 'layers.15.attention.wqkv.lora_B', 'layers.15.attention.wo.lora_A', 'layers.15.attention.wo.lora_B', 'layers.15.feed_forward.w1.lora_A', 'layers.15.feed_forward.w1.lora_B', 'layers.15.feed_forward.w3.lora_A', 'layers.15.feed_forward.w3.lora_B', 'layers.15.feed_forward.w2.lora_A', 'layers.15.feed_forward.w2.lora_B', 'layers.16.attention.wqkv.lora_A', 'layers.16.attention.wqkv.lora_B', 'layers.16.attention.wo.lora_A', 'layers.16.attention.wo.lora_B', 'layers.16.feed_forward.w1.lora_A', 'layers.16.feed_forward.w1.lora_B', 'layers.16.feed_forward.w3.lora_A', 'layers.16.feed_forward.w3.lora_B', 'layers.16.feed_forward.w2.lora_A', 'layers.16.feed_forward.w2.lora_B', 'layers.17.attention.wqkv.lora_A', 'layers.17.attention.wqkv.lora_B', 'layers.17.attention.wo.lora_A', 'layers.17.attention.wo.lora_B', 'layers.17.feed_forward.w1.lora_A', 'layers.17.feed_forward.w1.lora_B', 'layers.17.feed_forward.w3.lora_A', 'layers.17.feed_forward.w3.lora_B', 'layers.17.feed_forward.w2.lora_A', 'layers.17.feed_forward.w2.lora_B', 'layers.18.attention.wqkv.lora_A', 'layers.18.attention.wqkv.lora_B', 'layers.18.attention.wo.lora_A', 'layers.18.attention.wo.lora_B', 'layers.18.feed_forward.w1.lora_A', 'layers.18.feed_forward.w1.lora_B', 'layers.18.feed_forward.w3.lora_A', 'layers.18.feed_forward.w3.lora_B', 'layers.18.feed_forward.w2.lora_A', 'layers.18.feed_forward.w2.lora_B', 'layers.19.attention.wqkv.lora_A', 'layers.19.attention.wqkv.lora_B', 'layers.19.attention.wo.lora_A', 'layers.19.attention.wo.lora_B', 'layers.19.feed_forward.w1.lora_A', 'layers.19.feed_forward.w1.lora_B', 'layers.19.feed_forward.w3.lora_A', 'layers.19.feed_forward.w3.lora_B', 'layers.19.feed_forward.w2.lora_A', 'layers.19.feed_forward.w2.lora_B', 'layers.20.attention.wqkv.lora_A', 'layers.20.attention.wqkv.lora_B', 'layers.20.attention.wo.lora_A', 'layers.20.attention.wo.lora_B', 'layers.20.feed_forward.w1.lora_A', 'layers.20.feed_forward.w1.lora_B', 'layers.20.feed_forward.w3.lora_A', 'layers.20.feed_forward.w3.lora_B', 'layers.20.feed_forward.w2.lora_A', 'layers.20.feed_forward.w2.lora_B', 'layers.21.attention.wqkv.lora_A', 'layers.21.attention.wqkv.lora_B', 'layers.21.attention.wo.lora_A', 'layers.21.attention.wo.lora_B', 'layers.21.feed_forward.w1.lora_A', 'layers.21.feed_forward.w1.lora_B', 'layers.21.feed_forward.w3.lora_A', 'layers.21.feed_forward.w3.lora_B', 'layers.21.feed_forward.w2.lora_A', 'layers.21.feed_forward.w2.lora_B', 'layers.22.attention.wqkv.lora_A', 'layers.22.attention.wqkv.lora_B', 'layers.22.attention.wo.lora_A', 'layers.22.attention.wo.lora_B', 'layers.22.feed_forward.w1.lora_A', 'layers.22.feed_forward.w1.lora_B', 'layers.22.feed_forward.w3.lora_A', 'layers.22.feed_forward.w3.lora_B', 'layers.22.feed_forward.w2.lora_A', 'layers.22.feed_forward.w2.lora_B', 'layers.23.attention.wqkv.lora_A', 'layers.23.attention.wqkv.lora_B', 'layers.23.attention.wo.lora_A', 'layers.23.attention.wo.lora_B', 'layers.23.feed_forward.w1.lora_A', 'layers.23.feed_forward.w1.lora_B', 'layers.23.feed_forward.w3.lora_A', 'layers.23.feed_forward.w3.lora_B', 'layers.23.feed_forward.w2.lora_A', 'layers.23.feed_forward.w2.lora_B', 'output.lora_A', 'output.lora_B', 'fast_embeddings.lora_A', 'fast_embeddings.lora_B', 'fast_layers.0.attention.wqkv.lora_A', 'fast_layers.0.attention.wqkv.lora_B', 'fast_layers.0.attention.wo.lora_A', 'fast_layers.0.attention.wo.lora_B', 'fast_layers.0.feed_forward.w1.lora_A', 'fast_layers.0.feed_forward.w1.lora_B', 'fast_layers.0.feed_forward.w3.lora_A', 'fast_layers.0.feed_forward.w3.lora_B', 'fast_layers.0.feed_forward.w2.lora_A', 'fast_layers.0.feed_forward.w2.lora_B', 'fast_layers.1.attention.wqkv.lora_A', 'fast_layers.1.attention.wqkv.lora_B', 'fast_layers.1.attention.wo.lora_A', 'fast_layers.1.attention.wo.lora_B', 'fast_layers.1.feed_forward.w1.lora_A', 'fast_layers.1.feed_forward.w1.lora_B', 'fast_layers.1.feed_forward.w3.lora_A', 'fast_layers.1.feed_forward.w3.lora_B', 'fast_layers.1.feed_forward.w2.lora_A', 'fast_layers.1.feed_forward.w2.lora_B', 'fast_layers.2.attention.wqkv.lora_A', 'fast_layers.2.attention.wqkv.lora_B', 'fast_layers.2.attention.wo.lora_A', 'fast_layers.2.attention.wo.lora_B', 'fast_layers.2.feed_forward.w1.lora_A', 'fast_layers.2.feed_forward.w1.lora_B', 'fast_layers.2.feed_forward.w3.lora_A', 'fast_layers.2.feed_forward.w3.lora_B', 'fast_layers.2.feed_forward.w2.lora_A', 'fast_layers.2.feed_forward.w2.lora_B', 'fast_layers.3.attention.wqkv.lora_A', 'fast_layers.3.attention.wqkv.lora_B', 'fast_layers.3.attention.wo.lora_A', 'fast_layers.3.attention.wo.lora_B', 'fast_layers.3.feed_forward.w1.lora_A', 'fast_layers.3.feed_forward.w1.lora_B', 'fast_layers.3.feed_forward.w3.lora_A', 'fast_layers.3.feed_forward.w3.lora_B', 'fast_layers.3.feed_forward.w2.lora_A', 'fast_layers.3.feed_forward.w2.lora_B', 'fast_output.lora_A', 'fast_output.lora_B'], unexpected_keys=[])\n",
            "[2025-02-11 08:07:24,384][__main__][INFO] - [rank: 0] Instantiating callbacks...\n",
            "[2025-02-11 08:07:24,385][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>\n",
            "[2025-02-11 08:07:24,388][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelSummary>\n",
            "[2025-02-11 08:07:24,388][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.LearningRateMonitor>\n",
            "[2025-02-11 08:07:24,389][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <fish_speech.callbacks.GradNormMonitor>\n",
            "[2025-02-11 08:07:24,390][__main__][INFO] - [rank: 0] Instantiating loggers...\n",
            "[2025-02-11 08:07:24,390][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>\n",
            "[2025-02-11 08:07:24,392][__main__][INFO] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>\n",
            "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "[2025-02-11 08:07:24,441][__main__][INFO] - [rank: 0] Logging hyperparameters!\n",
            "2025-02-11 08:07:24.699927: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-11 08:07:24.716999: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739261244.736854   92223 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739261244.742731   92223 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-11 08:07:24.762189: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-02-11 08:07:27,135][__main__][INFO] - [rank: 0] Starting training!\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "[2025-02-11 08:07:27,935][fish_speech.models.text2semantic.lit_module][INFO] - [rank: 0] Set weight decay: 0 for 432 parameters\n",
            "[2025-02-11 08:07:27,935][fish_speech.models.text2semantic.lit_module][INFO] - [rank: 0] Set weight decay: 0.0 for 61 parameters\n",
            "\n",
            "   | Name                      | Type              | Params | Mode \n",
            "-------------------------------------------------------------------------\n",
            "0  | model                     | DualARTransformer | 644 M  | train\n",
            "1  | model.embeddings          | Embedding         | 105 M  | train\n",
            "2  | model.codebook_embeddings | Embedding         | 8.5 M  | train\n",
            "3  | model.layers              | ModuleList        | 362 M  | train\n",
            "4  | model.norm                | RMSNorm           | 1.0 K  | train\n",
            "5  | model.output              | Linear            | 105 M  | train\n",
            "6  | model.fast_project_in     | Identity          | 0      | train\n",
            "7  | model.fast_embeddings     | Embedding         | 1.1 M  | train\n",
            "8  | model.fast_layers         | ModuleList        | 60.4 M | train\n",
            "9  | model.fast_norm           | RMSNorm           | 1.0 K  | train\n",
            "10 | model.fast_output         | Linear            | 1.1 M  | train\n",
            "-------------------------------------------------------------------------\n",
            "6.2 M     Trainable params\n",
            "637 M     Non-trainable params\n",
            "644 M     Total params\n",
            "2,576.370 Total estimated model params size (MB)\n",
            "433       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s][2025-02-11 08:07:29,851][fish_speech.utils.utils][ERROR] - [rank: 0] \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fish-speech/fish_speech/utils/utils.py\", line 69, in wrap\n",
            "    metric_dict, object_dict = task_func(cfg=cfg)\n",
            "                               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/fish-speech/fish_speech/train.py\", line 110, in train\n",
            "    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 539, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
            "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
            "    return function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 575, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 982, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1024, in _run_stage\n",
            "    self._run_sanity_check()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1053, in _run_sanity_check\n",
            "    val_loop.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/utilities.py\", line 179, in _decorator\n",
            "    return loop_run(self, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/evaluation_loop.py\", line 137, in run\n",
            "    batch, batch_idx, dataloader_idx = next(data_fetcher)\n",
            "                                       ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fetchers.py\", line 134, in __next__\n",
            "    batch = super().__next__()\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fetchers.py\", line 61, in __next__\n",
            "    batch = next(self.iterator)\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/combined_loader.py\", line 341, in __next__\n",
            "    out = next(self._iterator)\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/combined_loader.py\", line 142, in __next__\n",
            "    out = next(self.iterators[0])\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
            "    return self._process_data(data)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 715, in reraise\n",
            "    raise exception\n",
            "ZeroDivisionError: Caught ZeroDivisionError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 33, in fetch\n",
            "    data.append(next(self.dataset_iter))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 119, in __iter__\n",
            "    yield self.augment()\n",
            "          ^^^^^^^^^^^^^^\n",
            "  File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 265, in augment\n",
            "    response = self.sample_data()\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 162, in sample_data\n",
            "    self.init_mock_data_server()\n",
            "  File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 142, in init_mock_data_server\n",
            "    shard_proto_files = split_by_rank_worker(expanded_proto_files)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 49, in split_by_rank_worker\n",
            "    files = files * (total_devices // len(files) + 1)\n",
            "                     ~~~~~~~~~~~~~~^^~~~~~~~~~~~\n",
            "ZeroDivisionError: integer division or modulo by zero\n",
            "\n",
            "[2025-02-11 08:07:29,855][fish_speech.utils.utils][INFO] - [rank: 0] Output dir: results/my_fish_speech\n",
            "Error executing job with overrides: ['project=my_fish_speech', '+lora@model.model.lora_config=r_8_alpha_16']\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/train.py\", line 141, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "[rank0]:     _run_hydra(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "[rank0]:     _run_app(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "[rank0]:     run_and_report(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "[rank0]:     raise ex\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "[rank0]:     return func()\n",
            "[rank0]:            ^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "[rank0]:     lambda: hydra.run(\n",
            "[rank0]:             ^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "[rank0]:     _ = ret.return_value\n",
            "[rank0]:         ^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "[rank0]:     raise self._return_value\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "[rank0]:     ret.return_value = task_function(task_cfg)\n",
            "[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/train.py\", line 137, in main\n",
            "[rank0]:     train(cfg)\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/utils/utils.py\", line 80, in wrap\n",
            "[rank0]:     raise ex\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/utils/utils.py\", line 69, in wrap\n",
            "[rank0]:     metric_dict, object_dict = task_func(cfg=cfg)\n",
            "[rank0]:                                ^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/train.py\", line 110, in train\n",
            "[rank0]:     trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 539, in fit\n",
            "[rank0]:     call._call_and_handle_interrupt(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
            "[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
            "[rank0]:     return function(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 575, in _fit_impl\n",
            "[rank0]:     self._run(model, ckpt_path=ckpt_path)\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 982, in _run\n",
            "[rank0]:     results = self._run_stage()\n",
            "[rank0]:               ^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1024, in _run_stage\n",
            "[rank0]:     self._run_sanity_check()\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1053, in _run_sanity_check\n",
            "[rank0]:     val_loop.run()\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/utilities.py\", line 179, in _decorator\n",
            "[rank0]:     return loop_run(self, *args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/evaluation_loop.py\", line 137, in run\n",
            "[rank0]:     batch, batch_idx, dataloader_idx = next(data_fetcher)\n",
            "[rank0]:                                        ^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fetchers.py\", line 134, in __next__\n",
            "[rank0]:     batch = super().__next__()\n",
            "[rank0]:             ^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fetchers.py\", line 61, in __next__\n",
            "[rank0]:     batch = next(self.iterator)\n",
            "[rank0]:             ^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/combined_loader.py\", line 341, in __next__\n",
            "[rank0]:     out = next(self._iterator)\n",
            "[rank0]:           ^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/combined_loader.py\", line 142, in __next__\n",
            "[rank0]:     out = next(self.iterators[0])\n",
            "[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "[rank0]:     data = self._next_data()\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
            "[rank0]:     return self._process_data(data)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
            "[rank0]:     data.reraise()\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 715, in reraise\n",
            "[rank0]:     raise exception\n",
            "[rank0]: ZeroDivisionError: Caught ZeroDivisionError in DataLoader worker process 0.\n",
            "[rank0]: Original Traceback (most recent call last):\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
            "[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 33, in fetch\n",
            "[rank0]:     data.append(next(self.dataset_iter))\n",
            "[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 119, in __iter__\n",
            "[rank0]:     yield self.augment()\n",
            "[rank0]:           ^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 265, in augment\n",
            "[rank0]:     response = self.sample_data()\n",
            "[rank0]:                ^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 162, in sample_data\n",
            "[rank0]:     self.init_mock_data_server()\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 142, in init_mock_data_server\n",
            "[rank0]:     shard_proto_files = split_by_rank_worker(expanded_proto_files)\n",
            "[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/fish-speech/fish_speech/datasets/semantic.py\", line 49, in split_by_rank_worker\n",
            "[rank0]:     files = files * (total_devices // len(files) + 1)\n",
            "[rank0]:                      ~~~~~~~~~~~~~~^^~~~~~~~~~~~\n",
            "[rank0]: ZeroDivisionError: integer division or modulo by zero\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ZeroDivisionError: integer division or modulo by zero ÏóêÎü¨\n"
      ],
      "metadata": {
        "id": "QgI0OPIxlOHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ïù¥Îäî Îç∞Ïù¥ÌÑ∞ÏÖãÏù¥ ÎÑàÎ¨¥ Ï†ÅÍ±∞ÎÇò, ÌäπÏ†ï Ïó∞ÏÇ∞ÏóêÏÑú 0Ïù¥ ÎÇòÏôÄÏÑú Î∞úÏÉùÌïòÎäî Î¨∏Ï†úÎùºÍ≥† Ìï®\n",
        "> ÏïÑÎûòÎäî .lab ÌååÏùºÏù¥ Î∂ÄÏ°±Ìï¥ÏÑú LoRA Fine-tuningÏù¥ Ïã§Ìå®ÌïòÎäî Í≤É Í∞ôÏïÑ Ïã§ÌñâÌïú ÎÇ¥Ïö©\n",
        "\n",
        "(.lab ÌååÏùºÏùÑ Îçî ÏÉùÏÑ±ÌïòÍ≥†, npy ÌååÏùºÏùÑ Í∑∏Ïóê ÎßûÍ≤å ÎßåÎì§Ïñ¥Ï§å. npyÌååÏùºÏùÄ 1.wav ÌååÏùº(3Î∂Ñ Î∂ÑÎüâ)ÏùÑ 1/10Î°ú ÎÇòÎà†ÏÑú Í∞ÄÏ†∏Í∞ê)"
      ],
      "metadata": {
        "id": "pNZRUTbjl_Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Í≥†Í∞ùÎãò, Ïñ¥Îñ§ Î≥¥Ìóò ÏÉÅÎã¥ÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\" > /content/fish-speech/data/SPK1/2.lab\n",
        "!echo \"Î≥¥Ìóò Ï≤≠Íµ¨Î•º ÏßÑÌñâÌïòÎ†§Î©¥ Î™á Í∞ÄÏßÄ ÏÑúÎ•òÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.\" > /content/fish-speech/data/SPK1/3.lab\n",
        "!echo \"Í∏¥Í∏â Ï∂úÎèô ÏÑúÎπÑÏä§Í∞Ä ÌïÑÏöîÌïòÏã†Í∞ÄÏöî?\" > /content/fish-speech/data/SPK1/4.lab\n",
        "!echo \"ÌòÑÏû¨ Í∞ÄÏûÖÌïòÏã† Î≥¥Ìóò Î≥¥Ïû• ÎÇ¥Ïó≠ÏùÑ ÌôïÏù∏Ìï¥ÎìúÎ¶¥ÍπåÏöî?\" > /content/fish-speech/data/SPK1/5.lab\n",
        "!echo \"Î≥¥ÌóòÎ£å Ìï†Ïù∏ ÌòúÌÉùÏù¥ Ï†ÅÏö©Îê† Ïàò ÏûàÎäîÏßÄ ÌôïÏù∏Ìï¥Î≥¥Í≤†ÏäµÎãàÎã§.\" > /content/fish-speech/data/SPK1/6.lab\n",
        "!echo \"ÏÇ¨Í≥† Ï†ëÏàòÎäî Ïï±ÏùÑ ÌÜµÌï¥ÏÑúÎèÑ Í∞ÄÎä•Ìï©ÎãàÎã§. ÏïàÎÇ¥Ìï¥ÎìúÎ¶¥ÍπåÏöî?\" > /content/fish-speech/data/SPK1/7.lab\n",
        "!echo \"Î≥¥Ìóò Í∞±Ïã† Ïãú Î≥ÄÍ≤ΩÎêú ÏÇ¨Ìï≠Ïù¥ ÏûàÏùÑ Ïàò ÏûàÏúºÎãà ÌôïÏù∏ Î∂ÄÌÉÅÎìúÎ¶ΩÎãàÎã§.\" > /content/fish-speech/data/SPK1/8.lab\n",
        "!echo \"Í≥†Í∞ùÎãòÍªò Ï†ÅÌï©Ìïú Î≥¥Ìóò ÏÉÅÌíàÏùÑ Ï∂îÏ≤úÌï¥ÎìúÎ¶¥ Ïàò ÏûàÏäµÎãàÎã§.\" > /content/fish-speech/data/SPK1/9.lab\n",
        "!echo \"Ï∂îÍ∞Ä ÌäπÏïΩÏùÑ ÏõêÌïòÏãúÎ©¥ ÏòµÏÖòÏùÑ ÏÑ§Î™ÖÌï¥ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§.\" > /content/fish-speech/data/SPK1/10.lab\n",
        "!echo \"ÏµúÍ∑º ÏÇ¨Í≥† Ïù¥Î†•Ïù¥ ÏûàÏúºÏã†Í∞ÄÏöî? Î≥¥ÌóòÎ£åÏóê ÏòÅÌñ•ÏùÑ Ï§Ñ Ïàò ÏûàÏäµÎãàÎã§.\" > /content/fish-speech/data/SPK1/11.lab"
      ],
      "metadata": {
        "id": "uQlGTEoBNWFC"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/fish-speech/data/SPK1/\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "wav_path = \"/content/data-raw/1.wav\"\n",
        "output_dir = \"/content/fish-speech/data/SPK1/\"\n",
        "\n",
        "# Ïò§ÎîîÏò§ Î°úÎìú (16kHz ÏÉòÌîåÎßÅ)\n",
        "y, sr = librosa.load(wav_path, sr=16000)\n",
        "\n",
        "# 18Ï¥àÏî© ÎÇòÎàÑÍ∏∞ (18Ï¥à * 16000Hz = 288000 samples)\n",
        "segment_length = sr * 18\n",
        "\n",
        "# Ïò§ÎîîÏò§Î•º Ïó¨Îü¨ Í∞ú segmentÎ°ú ÎÇòÎàÑÍ∏∞\n",
        "segments = [y[i : i + segment_length] for i in range(0, len(y), segment_length)]\n",
        "\n",
        "# Í∏∞Ï°¥Ïóê Ï°¥Ïû¨ÌïòÎäî 1.npy Ïù¥ÌõÑ Î≤àÌò∏Î∂ÄÌÑ∞ ÏãúÏûë\n",
        "start_idx = 2 if os.path.exists(os.path.join(output_dir, \"1.npy\")) else 1\n",
        "\n",
        "# lab ÌååÏùº Î¶¨Ïä§Ìä∏ (ÏÇ¨Ï†ÑÏóê ÎßåÎì§Ïñ¥ÏßÑ ÌÖçÏä§Ìä∏ ÌååÏùºÎì§)\n",
        "lab_files = sorted([f for f in os.listdir(output_dir) if f.endswith(\".lab\")])\n",
        "\n",
        "# segment Í∞úÏàòÏôÄ .lab ÌååÏùº Í∞úÏàòÎ•º ÎßûÏ∂îÍ∏∞ ÏúÑÌï¥ Ï°∞Ï†ï\n",
        "num_files = min(len(segments), len(lab_files))\n",
        "\n",
        "for i in range(num_files):\n",
        "    npy_filename = os.path.join(output_dir, f\"{start_idx + i}.npy\")\n",
        "    np.save(npy_filename, segments[i])\n",
        "    print(f\"‚úÖ Saved: {npy_filename}\")\n",
        "\n",
        "print(\"üéâ Î™®Îì† .npy ÌååÏùºÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtW7SC12WdtA",
        "outputId": "44c8a753-e6aa-40fc-dba5-93570b64bde7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved: /content/fish-speech/data/SPK1/2.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/3.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/4.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/5.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/6.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/7.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/8.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/9.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/10.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/11.npy\n",
            "‚úÖ Saved: /content/fish-speech/data/SPK1/12.npy\n",
            "üéâ Î™®Îì† .npy ÌååÏùºÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÌôïÏù∏Ïö© ÏÖÄ"
      ],
      "metadata": {
        "id": "vxyojfW6mRlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "npy_dir = \"/content/fish-speech/data/SPK1\"\n",
        "npy_files = [f for f in os.listdir(npy_dir) if f.endswith(\".npy\")]\n",
        "\n",
        "for npy_file in npy_files:\n",
        "    path = os.path.join(npy_dir, npy_file)\n",
        "    data = np.load(path)\n",
        "\n",
        "    if data.size == 0:\n",
        "        print(f\"‚ö†Ô∏è Í≤ΩÍ≥†: {npy_file} ÌååÏùºÏù¥ ÎπÑÏñ¥ ÏûàÏäµÎãàÎã§.\")\n",
        "    else:\n",
        "        print(f\"‚úÖ {npy_file} ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSDDPIHhm9ix",
        "outputId": "1ce9efdd-bb06-4767-a85d-1ccaf9d035f6"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 3.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 11.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 2.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 4.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 8.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 5.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 10.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 6.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 9.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n",
            "‚úÖ 7.npy ÌååÏùº Ï†ïÏÉÅ Î°úÎìúÎê®. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (288000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/fish-speech/data/SPK1/*.npy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QxGNMJdrjog",
        "outputId": "e10ab326-a33f-4482-f317-1dca43bd7e36"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/10.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/11.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/2.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/3.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/4.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/5.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/6.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/7.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/8.npy\n",
            "-rw-r--r-- 1 root root 1152128 Feb 11 06:01 /content/fish-speech/data/SPK1/9.npy\n"
          ]
        }
      ]
    }
  ]
}